{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798db4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pan12-text-alignment-partition-01-20250609-test',\n",
       "       'llm-plagiarism-detection-partition-01-20250527-test',\n",
       "       'llm-plagiarism-detection-partition-02-20250527-test'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = \n",
    "df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79ec4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DISPLAY_NAMES = {\n",
    "    'pan12-text-alignment-partition-01-20250609-test': \"pan12-plagiarism\",\n",
    "    'llm-plagiarism-detection-partition-01-20250527-test': \"llm-plagiarism\",\n",
    "    'llm-plagiarism-detection-partition-02-20250527-test': \"llm-plagiarism\",\n",
    "}\n",
    "\n",
    "TEAM_TO_Paper = {\n",
    "    \"foshan-university\": \"Tang\",\n",
    "    \"chi-zi-zhi-xin-dui\": \"Su\",\n",
    "    \"jrluo\": \"Jieren\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95385900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Micro Plagdet</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Plagdet</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Granularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>pan12-plagiarism</td>\n",
       "      <td>0.291774</td>\n",
       "      <td>0.345830</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>0.216836</td>\n",
       "      <td>0.239681</td>\n",
       "      <td>0.932322</td>\n",
       "      <td>2.383721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.081683</td>\n",
       "      <td>0.077721</td>\n",
       "      <td>0.589433</td>\n",
       "      <td>0.057207</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.539587</td>\n",
       "      <td>2.199965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tang</td>\n",
       "      <td>pan12-plagiarism</td>\n",
       "      <td>0.026082</td>\n",
       "      <td>0.028616</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>1.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tang</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.417315</td>\n",
       "      <td>0.568960</td>\n",
       "      <td>0.329815</td>\n",
       "      <td>0.308857</td>\n",
       "      <td>0.563260</td>\n",
       "      <td>0.212855</td>\n",
       "      <td>1.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jieren</td>\n",
       "      <td>pan12-plagiarism</td>\n",
       "      <td>0.079933</td>\n",
       "      <td>0.098074</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>0.077865</td>\n",
       "      <td>0.095370</td>\n",
       "      <td>0.973704</td>\n",
       "      <td>3.694915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jieren</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.156255</td>\n",
       "      <td>0.120932</td>\n",
       "      <td>0.533642</td>\n",
       "      <td>0.135510</td>\n",
       "      <td>0.101916</td>\n",
       "      <td>0.531639</td>\n",
       "      <td>1.392566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yukino</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.486431</td>\n",
       "      <td>0.496170</td>\n",
       "      <td>0.480868</td>\n",
       "      <td>0.452510</td>\n",
       "      <td>0.460152</td>\n",
       "      <td>0.450739</td>\n",
       "      <td>1.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Su</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.424009</td>\n",
       "      <td>0.381642</td>\n",
       "      <td>0.670325</td>\n",
       "      <td>0.339859</td>\n",
       "      <td>0.315849</td>\n",
       "      <td>0.509543</td>\n",
       "      <td>1.207905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission           dataset  Micro Plagdet  Micro Recall  Micro Precision  \\\n",
       "0   baseline  pan12-plagiarism       0.291774      0.345830         0.993889   \n",
       "1   baseline    llm-plagiarism       0.081683      0.077721         0.589433   \n",
       "2       Tang  pan12-plagiarism       0.026082      0.028616         0.025199   \n",
       "3       Tang    llm-plagiarism       0.417315      0.568960         0.329815   \n",
       "4     Jieren  pan12-plagiarism       0.079933      0.098074         0.982090   \n",
       "5     Jieren    llm-plagiarism       0.156255      0.120932         0.533642   \n",
       "6     yukino    llm-plagiarism       0.486431      0.496170         0.480868   \n",
       "7         Su    llm-plagiarism       0.424009      0.381642         0.670325   \n",
       "\n",
       "   Macro Plagdet  Macro Recall  Macro Precision  Granularity  \n",
       "0       0.216836      0.239681         0.932322     2.383721  \n",
       "1       0.057207      0.052800         0.539587     2.199965  \n",
       "2       0.026752      0.041857         0.020462     1.038462  \n",
       "3       0.308857      0.563260         0.212855     1.000236  \n",
       "4       0.077865      0.095370         0.973704     3.694915  \n",
       "5       0.135510      0.101916         0.531639     1.392566  \n",
       "6       0.452510      0.460152         0.450739     1.000425  \n",
       "7       0.339859      0.315849         0.509543     1.207905  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "from statistics import mean\n",
    "resources = {}\n",
    "\n",
    "for _, i in pd.read_json(\"runs.jsonl\", lines=True).iterrows():\n",
    "    if i[\"team\"] not in results:\n",
    "        results[i[\"team\"]] = {}\n",
    "    dataset = DATASET_DISPLAY_NAMES[i[\"dataset\"]]\n",
    "    if dataset not in results[i[\"team\"]]:\n",
    "        results[i[\"team\"]][dataset] = []\n",
    "    \n",
    "    results[i[\"team\"]][dataset] += [i[\"evaluation\"]]\n",
    "\n",
    "df = []\n",
    "\n",
    "for submission in results:\n",
    "    for dataset in results[submission]:\n",
    "        i = {\"submission\": TEAM_TO_Paper.get(submission, submission), \"dataset\": dataset}\n",
    "        for measure in results[submission][dataset][0].keys():\n",
    "            i[measure] = mean(k[measure] for k in results[submission][dataset])\n",
    "        df += [i]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "253a7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Score\"] = (df[\"Micro Plagdet\"] + df[\"Macro Plagdet\"] + df[\"Macro Precision\"] + df[\"Micro Precision\"] + df[\"Macro Recall\"] + df[\"Micro Recall\"])/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12078907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.233072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jieren</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.263316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tang</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.400177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Su</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.440204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yukino</td>\n",
       "      <td>llm-plagiarism</td>\n",
       "      <td>0.471145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission         dataset     Score\n",
       "1   baseline  llm-plagiarism  0.233072\n",
       "5     Jieren  llm-plagiarism  0.263316\n",
       "3       Tang  llm-plagiarism  0.400177\n",
       "7         Su  llm-plagiarism  0.440204\n",
       "6     yukino  llm-plagiarism  0.471145"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"dataset\"] == \"llm-plagiarism\"][[\"submission\", \"dataset\", \"Score\"]].sort_values(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e889452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tang</td>\n",
       "      <td>pan12-plagiarism</td>\n",
       "      <td>0.028161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jieren</td>\n",
       "      <td>pan12-plagiarism</td>\n",
       "      <td>0.384506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>pan12-plagiarism</td>\n",
       "      <td>0.503389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission           dataset     Score\n",
       "2       Tang  pan12-plagiarism  0.028161\n",
       "4     Jieren  pan12-plagiarism  0.384506\n",
       "0   baseline  pan12-plagiarism  0.503389"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"dataset\"] == \"pan12-plagiarism\"][[\"submission\", \"dataset\", \"Score\"]].sort_values(\"Score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
