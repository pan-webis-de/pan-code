{"task": "pan25-generated-plagiarism-detection", "dataset": "pan12-text-alignment-partition-01-20250609-test", "team": "baseline", "software": "pan12-text-alignment-baseline", "vm": "baseline", "run_id": "2025-06-09-08-20-27", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4138.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": true, "review_blinded": false, "evaluation": {"Micro Plagdet": 0.2917744530210344, "Micro Recall": 0.3458301417249684, "Micro Precision": 0.9938888884884334, "Macro Plagdet": 0.21683567893688008, "Macro Recall": 0.23968070036014583, "Macro Precision": 0.9323224932600144, "Granularity": 2.383720930232558}, "used_resources": {"wallcock": "384185 ms", "CPU (Max)": 232, "RAM (Max)": 20447, "GPU Utilization (Max)": 0, "GPU VRAM (Max)": 664}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.03394900354550551, "Micro Recall": 0.12057142071846742, "Micro Precision": 0.06324113805936529, "Macro Plagdet": 0.056658758913380035, "Macro Recall": 0.07783454496904649, "Macro Precision": 0.626427208856367, "Granularity": 4.440860215053763}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "pan12-text-alignment-partition-01-20250609-test", "team": "foshan-university", "software": "booming-bridge", "vm": "foshan-university", "run_id": "2025-06-09-08-21-36", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4326.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": true, "review_blinded": false, "evaluation": {"Micro Plagdet": 0.026081938902326577, "Micro Recall": 0.02861562200120491, "Micro Precision": 0.025198712268522404, "Macro Plagdet": 0.026751930762663172, "Macro Recall": 0.04185679926224359, "Macro Precision": 0.020462266963296123, "Granularity": 1.0384615384615385}, "used_resources": {"wallcock": "179181 ms", "CPU (Max)": 10, "RAM (Max)": 20447, "GPU Utilization (Max)": 100, "GPU VRAM (Max)": 3533}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.01185010518880706, "Micro Recall": 0.04279196327955364, "Micro Precision": 0.006877295339836189, "Macro Plagdet": 0.005935596161151413, "Macro Recall": 0.0311284046692607, "Macro Precision": 0.00328056923553399, "Granularity": 1.0}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "pan12-text-alignment-partition-01-20250609-test", "team": "jrluo", "software": "balanced-fencing", "vm": "jrluo", "run_id": "2025-06-09-08-22-15", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4313.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": true, "review_blinded": false, "evaluation": {"Micro Plagdet": 0.07993312688570108, "Micro Recall": 0.09807404932709107, "Micro Precision": 0.9820898446329812, "Macro Plagdet": 0.07786528042258883, "Macro Recall": 0.09537041896638221, "Macro Precision": 0.9737043459936323, "Granularity": 3.694915254237288}, "used_resources": {"wallcock": "206174 ms", "CPU (Max)": 19, "RAM (Max)": 19660, "GPU Utilization (Max)": 100, "GPU VRAM (Max)": 3508}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.06892295020543282, "Micro Recall": 0.08775527031855537, "Micro Precision": 0.16038015441261422, "Macro Plagdet": 0.057210819245378755, "Macro Recall": 0.06135405529238848, "Macro Precision": 0.20238945735405722, "Granularity": 2.1294117647058823}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-01-20250527-test", "team": "foshan-university", "software": "booming-bridge", "vm": "foshan-university", "run_id": "2025-06-01-14-35-26", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4326.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.3973194090681334, "Micro Recall": 0.5260344463364693, "Micro Precision": 0.3192476286252436, "Macro Plagdet": 0.28240274422908573, "Macro Recall": 0.5257352768663378, "Macro Precision": 0.19306919600570793, "Granularity": 1.0000971062342203}, "used_resources": {"wallcock": "858111 ms", "CPU (Max)": 10, "RAM (Max)": 19660, "GPU Utilization (Max)": 100, "GPU VRAM (Max)": 3535}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.15862311550193095, "Micro Recall": 0.5574814246731222, "Micro Precision": 0.09246655480959184, "Macro Plagdet": 0.09775333321434684, "Macro Recall": 0.536598689002185, "Macro Precision": 0.05377480207970691, "Granularity": 1.0}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.08389751058085931, "Micro Recall": 0.5307095095706459, "Micro Precision": 0.04554908132930691, "Macro Plagdet": 0.048398719552439476, "Macro Recall": 0.5169582292038558, "Macro Precision": 0.025387788944951164, "Granularity": 1.0}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.02867791394441551, "Micro Recall": 0.5559166446929149, "Micro Precision": 0.014740784824509988, "Macro Plagdet": 0.016947351839575475, "Macro Recall": 0.5481743894771384, "Macro Precision": 0.008619555273782602, "Granularity": 1.0020366598778003}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.12704813610818866, "Micro Recall": 0.4927769902562691, "Micro Precision": 0.07292483625722984, "Macro Plagdet": 0.08369825380665712, "Macro Recall": 0.51246848611329, "Macro Precision": 0.045570498301035024, "Granularity": 1.0}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.08726541848581837, "Micro Recall": 0.5083948556847001, "Micro Precision": 0.04772902674736132, "Macro Plagdet": 0.057187932914496635, "Macro Recall": 0.5171641791044777, "Macro Precision": 0.030267451447927845, "Granularity": 1.0}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.02344510147759407, "Micro Recall": 0.46805286626890424, "Micro Precision": 0.012023688294525797, "Macro Plagdet": 0.014196666937723347, "Macro Recall": 0.4853658536585366, "Macro Precision": 0.007203685256110741, "Granularity": 1.0}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.041904260135545504, "Micro Recall": 0.5495403678398294, "Micro Precision": 0.021782628597643888, "Macro Plagdet": 0.028619854576824682, "Macro Recall": 0.5743174924165824, "Macro Precision": 0.01467559023968476, "Granularity": 1.0}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.023644513391935587, "Micro Recall": 0.5727041707080505, "Micro Precision": 0.012071445963608084, "Macro Plagdet": 0.01584043381773826, "Macro Recall": 0.5788336933045356, "Macro Precision": 0.008030093165915237, "Granularity": 1.0}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.007463192231287384, "Micro Recall": 0.526392802327446, "Micro Precision": 0.0037582382490272135, "Macro Plagdet": 0.0044338836067601564, "Macro Recall": 0.5161290322580645, "Macro Precision": 0.0022265053669756063, "Granularity": 1.0}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-01-20250527-test", "team": "yukino", "software": "online-auditor", "vm": "yukino", "run_id": "2025-05-30-13-23-00", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4323.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.5343389723682657, "Micro Recall": 0.5752755872992336, "Micro Precision": 0.4991549267780531, "Macro Plagdet": 0.4922610732977802, "Macro Recall": 0.5360697072684264, "Macro Precision": 0.45535495669231, "Granularity": 1.0004665484743864}, "used_resources": {}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.24648819637995953, "Micro Recall": 0.6431031399177153, "Micro Precision": 0.15250385678651204, "Macro Plagdet": 0.18641064468290766, "Macro Recall": 0.5867156709380716, "Macro Precision": 0.11083760690979608, "Granularity": 1.0003088326127239}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.135531057808985, "Micro Recall": 0.6200211667334032, "Micro Precision": 0.07608082094163465, "Macro Plagdet": 0.10632508342114166, "Macro Recall": 0.5680474692555111, "Macro Precision": 0.05865164362428242, "Granularity": 1.0}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.04154795873613487, "Micro Recall": 0.5687516287561623, "Micro Precision": 0.02156152648658002, "Macro Plagdet": 0.01956894932758536, "Macro Recall": 0.5064907513181673, "Macro Precision": 0.009977216227461339, "Granularity": 1.0}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.17721615412302585, "Micro Recall": 0.5078097251638196, "Micro Precision": 0.10744147885475508, "Macro Plagdet": 0.20436133656140373, "Macro Recall": 0.4966749967386298, "Macro Precision": 0.12877674916217471, "Granularity": 1.001109057301294}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.12508682622987352, "Micro Recall": 0.5285094089890938, "Micro Precision": 0.07093818560627982, "Macro Plagdet": 0.1354640357785001, "Macro Recall": 0.5018258865189046, "Macro Precision": 0.07830029949578801, "Granularity": 1.0}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.028993292114978933, "Micro Recall": 0.4100597757791503, "Micro Precision": 0.015060378657809065, "Macro Plagdet": 0.025715873960174454, "Macro Recall": 0.39863264562637296, "Macro Precision": 0.01331509872707065, "Granularity": 1.0028901734104045}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.06649407145030353, "Micro Recall": 0.6199203335202155, "Micro Precision": 0.0351311599705604, "Macro Plagdet": 0.06449370358673404, "Macro Recall": 0.5816242198510495, "Macro Precision": 0.03413964809522377, "Granularity": 1.0}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.03923813296212457, "Micro Recall": 0.6706527643064986, "Micro Precision": 0.02021029205183381, "Macro Plagdet": 0.03666744026238798, "Macro Recall": 0.6045919989056118, "Macro Precision": 0.018907060083939088, "Granularity": 1.0}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.01072987153041678, "Micro Recall": 0.5309514809978696, "Micro Precision": 0.005419698460383685, "Macro Plagdet": 0.008460969805588777, "Macro Recall": 0.5031383984083387, "Macro Precision": 0.004266357259251954, "Granularity": 1.0}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-01-20250527-test", "team": "jrluo", "software": "balanced-fencing", "vm": "jrluo", "run_id": "2025-05-29-11-22-08", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4313.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.17441054099194886, "Micro Recall": 0.13839709398091407, "Micro Precision": 0.5569508781205306, "Macro Plagdet": 0.15083271515879326, "Macro Recall": 0.11631579682335232, "Macro Precision": 0.545272571894162, "Granularity": 1.4135492276195794}, "used_resources": {"wallcock": "452263 ms", "CPU (Max)": 10, "RAM (Max)": 19660, "GPU Utilization (Max)": 100, "GPU VRAM (Max)": 3508}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.1766888731810444, "Micro Recall": 0.2209400487880817, "Micro Precision": 0.24299936962401122, "Macro Plagdet": 0.16543318089997008, "Macro Recall": 0.1967555157803666, "Macro Precision": 0.24114749284372594, "Granularity": 1.4792485801660114}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.09276794445420576, "Micro Recall": 0.16550165467829828, "Micro Precision": 0.09418928903077997, "Macro Plagdet": 0.08027984461896566, "Macro Recall": 0.1258546141882583, "Macro Precision": 0.0884570008314977, "Granularity": 1.452296819787986}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.03220035182779079, "Micro Recall": 0.13994427148146263, "Micro Precision": 0.024606082789379858, "Macro Plagdet": 0.0275397256680829, "Macro Recall": 0.09587477363347542, "Macro Precision": 0.022005706874103862, "Granularity": 1.4619047619047618}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.06422375279494398, "Micro Recall": 0.07033332260382287, "Micro Precision": 0.0690180368871627, "Macro Plagdet": 0.06343701901985349, "Macro Recall": 0.06855491799180326, "Macro Precision": 0.0690791371841606, "Granularity": 1.1210710128055879}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.05209374183653619, "Micro Recall": 0.08135845532913279, "Micro Precision": 0.05064779605642204, "Macro Plagdet": 0.04120408197848804, "Macro Recall": 0.05847342183674326, "Macro Precision": 0.04273463759498092, "Granularity": 1.29490022172949}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.004499731973449463, "Micro Recall": 0.017473532246370757, "Micro Precision": 0.002976459184849286, "Macro Plagdet": 0.0045306122453282055, "Macro Recall": 0.011886632932139483, "Macro Precision": 0.003263803920004774, "Granularity": 1.1891891891891893}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.053686873634331715, "Micro Recall": 0.17381486698441795, "Micro Precision": 0.045685042465651284, "Macro Plagdet": 0.054844939267177456, "Macro Recall": 0.15177525292545643, "Macro Precision": 0.04885224779352497, "Granularity": 1.5450346420323327}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.029906789025303082, "Micro Recall": 0.1698729388942774, "Micro Precision": 0.02374267103185093, "Macro Plagdet": 0.02656033123937093, "Macro Recall": 0.12638191811433272, "Macro Precision": 0.021672764505325525, "Granularity": 1.6263736263736264}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.009328805752424714, "Micro Recall": 0.1529419512977344, "Micro Precision": 0.007240647728274058, "Macro Plagdet": 0.010490494880276468, "Macro Recall": 0.13858124630390825, "Macro Precision": 0.00823629954553727, "Granularity": 1.7936507936507937}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-01-20250527-test", "team": "chi-zi-zhi-xin-dui", "software": "internal-event", "vm": "chi-zi-zhi-xin-dui", "run_id": "2025-05-27-22-23-10", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4304.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.45680628844571913, "Micro Recall": 0.42968476007128215, "Micro Precision": 0.6722025977828555, "Macro Plagdet": 0.36690138986236, "Macro Recall": 0.35751850567525256, "Macro Precision": 0.5121163217597147, "Granularity": 1.2155328115593016}, "used_resources": {"wallcock": "53475774 ms", "CPU (Max)": 20, "RAM (Max)": 19660, "GPU Utilization (Max)": 2885, "GPU VRAM (Max)": 5377}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.2673223701364531, "Micro Recall": 0.5242163640861442, "Micro Precision": 0.2241308247708399, "Macro Plagdet": 0.21677430161142935, "Macro Recall": 0.43840444317934324, "Macro Precision": 0.1794204723703293, "Granularity": 1.257360959651036}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.14814630230278455, "Micro Recall": 0.49324086604001766, "Micro Precision": 0.10912356461538356, "Macro Plagdet": 0.11954161791104882, "Macro Recall": 0.4022427209339025, "Macro Precision": 0.08784873879698721, "Granularity": 1.3074604370761116}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.04231548000524042, "Micro Recall": 0.39422838206880173, "Micro Precision": 0.02694607764785403, "Macro Plagdet": 0.03348587748495183, "Macro Recall": 0.30570417742197403, "Macro Precision": 0.02135338085741072, "Granularity": 1.284848484848485}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.1618592363615397, "Micro Recall": 0.3050248784192198, "Micro Precision": 0.11635821348266703, "Macro Plagdet": 0.12098689468587391, "Macro Recall": 0.24980892557231701, "Macro Precision": 0.08417254694213969, "Granularity": 1.057301293900185}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.13527839935067684, "Micro Recall": 0.3817224719507293, "Micro Precision": 0.09237743491090006, "Macro Plagdet": 0.09325355352017096, "Macro Recall": 0.32583198846836353, "Macro Precision": 0.060846729786401696, "Granularity": 1.1429924242424243}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.02570224923595345, "Micro Recall": 0.2185504671997224, "Micro Precision": 0.014472090811467362, "Macro Plagdet": 0.020150160370408666, "Macro Recall": 0.1843185350551042, "Macro Precision": 0.01129323601026501, "Granularity": 1.0794392523364487}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.08545931882150959, "Micro Recall": 0.5499271984745463, "Micro Precision": 0.05618917119869744, "Macro Plagdet": 0.062294829337583825, "Macro Recall": 0.5284441101440811, "Macro Precision": 0.03997257657139491, "Granularity": 1.286415711947627}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.04613688325328349, "Micro Recall": 0.5613743937924345, "Micro Precision": 0.030501295645134627, "Macro Plagdet": 0.032165342288167476, "Macro Recall": 0.5348865641890411, "Macro Precision": 0.020959110678153692, "Granularity": 1.385135135135135}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.01640227419287666, "Micro Recall": 0.5479606212631434, "Micro Precision": 0.010084641296991081, "Macro Plagdet": 0.010745600590445251, "Macro Recall": 0.5033250847891672, "Macro Precision": 0.006572052189067761, "Granularity": 1.309278350515464}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-01-20250527-test", "team": "baseline", "software": "pan12-text-alignment-baseline", "vm": "baseline", "run_id": "2025-05-27-22-21-39", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4138.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.09124758364020522, "Micro Recall": 0.08842475233886694, "Micro Precision": 0.6261404426090923, "Macro Plagdet": 0.06368555716815268, "Macro Recall": 0.05984021746672328, "Macro Precision": 0.5616325404668762, "Granularity": 2.2451654490760635}, "used_resources": {"wallcock": "356687 ms", "CPU (Max)": 20, "RAM (Max)": 5898}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.12473407616178969, "Micro Recall": 0.1704121768307271, "Micro Precision": 0.3297913855912554, "Macro Plagdet": 0.09480566935579839, "Macro Recall": 0.12221792438130778, "Macro Precision": 0.2834535741996559, "Granularity": 2.4858623939679547}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.06157232304587811, "Micro Recall": 0.10509690462130818, "Micro Precision": 0.1052439368813558, "Macro Plagdet": 0.042371730503307566, "Macro Recall": 0.06420888744104701, "Macro Precision": 0.08291894049299163, "Granularity": 2.267254038179148}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.027322651402810094, "Micro Recall": 0.10290654910323963, "Micro Precision": 0.031837455560665535, "Macro Plagdet": 0.01951391861177241, "Macro Recall": 0.05825731957053953, "Macro Precision": 0.024740603556793708, "Granularity": 2.433862433862434}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.02459376177387529, "Micro Recall": 0.02434889715598438, "Micro Precision": 0.04204252054752695, "Macro Plagdet": 0.022617274175904273, "Macro Recall": 0.019809348208119113, "Macro Precision": 0.04989663981622381, "Granularity": 1.3848439821693908}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.02125042114269075, "Micro Recall": 0.02894363317159172, "Micro Precision": 0.031704352240047785, "Macro Plagdet": 0.016348248372693247, "Macro Recall": 0.018079018914932004, "Macro Precision": 0.032683285243129884, "Granularity": 1.6833333333333333}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.001932908615535072, "Micro Recall": 0.004927860797482589, "Micro Precision": 0.001477017493306668, "Macro Plagdet": 0.0018343783625731217, "Macro Recall": 0.002614125656576421, "Macro Precision": 0.0018358843095820747, "Granularity": 1.2592592592592593}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.03784391497341779, "Micro Recall": 0.11111890503204763, "Micro Precision": 0.05139052418854682, "Macro Plagdet": 0.03369547262230049, "Macro Recall": 0.07524822226242976, "Macro Precision": 0.05355466018333338, "Granularity": 2.6226912928759893}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.020847436722205025, "Micro Recall": 0.1017090203685742, "Micro Precision": 0.025013405746628525, "Macro Plagdet": 0.017977383649255177, "Macro Recall": 0.061044204280058384, "Macro Precision": 0.02416561482361302, "Granularity": 2.8}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.007866181984725594, "Micro Recall": 0.09193812567292053, "Micro Precision": 0.007658688736692053, "Macro Plagdet": 0.00834625989436462, "Macro Recall": 0.06947186023017692, "Macro Precision": 0.008409216868566693, "Granularity": 2.4761904761904763}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-02-20250527-test", "team": "chi-zi-zhi-xin-dui", "software": "internal-event", "vm": "chi-zi-zhi-xin-dui", "run_id": "2025-05-27-22-23-31", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4304.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.3912111106477156, "Micro Recall": 0.3335982619669181, "Micro Precision": 0.6684473243187998, "Macro Plagdet": 0.3128167701862793, "Macro Recall": 0.274179142716745, "Macro Precision": 0.5069687423221101, "Granularity": 1.200277842093077}, "used_resources": {"wallcock": "54724287 ms", "CPU (Max)": 20, "RAM (Max)": 19660, "GPU Utilization (Max)": 3112, "GPU VRAM (Max)": 3112}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.23887985470918593, "Micro Recall": 0.40316368385060075, "Micro Precision": 0.2137767666719186, "Macro Plagdet": 0.18981020817529534, "Macro Recall": 0.3316657364209896, "Macro Precision": 0.16684466159151348, "Granularity": 1.2495426271496524}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.13937515945197884, "Micro Recall": 0.37696338266114104, "Micro Precision": 0.10846254162436579, "Macro Plagdet": 0.10979997644931415, "Macro Recall": 0.308797515413787, "Macro Precision": 0.08451574843038358, "Granularity": 1.311212814645309}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.035186041025212104, "Micro Recall": 0.26428523494359785, "Micro Precision": 0.023061745503627547, "Macro Plagdet": 0.028653594578238704, "Macro Recall": 0.21777290670191543, "Macro Precision": 0.018761033720932074, "Granularity": 1.3063973063973064}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.16348520619503637, "Micro Recall": 0.2504244368150617, "Micro Precision": 0.12690729335565712, "Macro Plagdet": 0.13017721214533073, "Macro Recall": 0.2102361768102323, "Macro Precision": 0.09848012144068942, "Granularity": 1.0425422860071758}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.14743034150538217, "Micro Recall": 0.3329306419894667, "Micro Precision": 0.10688405398149459, "Macro Plagdet": 0.10422794896195592, "Macro Recall": 0.2765307123232884, "Macro Precision": 0.07211701352606864, "Granularity": 1.139968895800933}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.0292445964518778, "Micro Recall": 0.17558912880758987, "Micro Precision": 0.017412013002678094, "Macro Plagdet": 0.024972458083263427, "Macro Recall": 0.15522166587260638, "Macro Precision": 0.014818399971389961, "Granularity": 1.1189591078066914}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.0723891287647557, "Micro Recall": 0.41679242392530946, "Micro Precision": 0.048340170543532686, "Macro Plagdet": 0.049296142046009746, "Macro Recall": 0.3693821962712391, "Macro Precision": 0.03205794188384435, "Granularity": 1.2922465208747516}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.03665772053210459, "Micro Recall": 0.4039469502444143, "Micro Precision": 0.02404638585489285, "Macro Plagdet": 0.0229640857370868, "Macro Recall": 0.35070003391515936, "Macro Precision": 0.014818151228126615, "Granularity": 1.3590909090909091}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.009546551690379565, "Micro Recall": 0.3253061902214163, "Micro Precision": 0.006177613443601574, "Macro Plagdet": 0.007463149280634481, "Macro Recall": 0.2787062035247364, "Macro Precision": 0.00482142136315272, "Granularity": 1.411764705882353}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-02-20250527-test", "team": "baseline", "software": "pan12-text-alignment-baseline", "vm": "baseline", "run_id": "2025-05-27-22-21-57", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4138.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.07211910828316107, "Micro Recall": 0.06701684472020647, "Micro Precision": 0.5527258179184243, "Macro Plagdet": 0.05072914583399614, "Macro Recall": 0.04575990802999987, "Macro Precision": 0.5175422209093563, "Granularity": 2.1547643131701397}, "used_resources": {"wallcock": "349369 ms", "CPU (Max)": 10, "RAM (Max)": 5898}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.09992011694496084, "Micro Recall": 0.12671282043779222, "Micro Precision": 0.276555322786556, "Macro Plagdet": 0.0782572677307897, "Macro Recall": 0.09389244311226239, "Macro Precision": 0.24735186141681173, "Granularity": 2.338835396607061}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.052312064493602484, "Micro Recall": 0.08091669287525362, "Micro Precision": 0.09582991441704894, "Macro Plagdet": 0.03615064895564679, "Macro Recall": 0.04998172361477846, "Macro Precision": 0.07706384307320137, "Granularity": 2.1983356449375866}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.017498787479592097, "Micro Recall": 0.05596110265730062, "Micro Precision": 0.020099622568123043, "Macro Plagdet": 0.014049789445933695, "Macro Recall": 0.03650802808695454, "Macro Precision": 0.01759617011842628, "Granularity": 2.226993865030675}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.024388936029922377, "Micro Recall": 0.02291543993974627, "Micro Precision": 0.04779917929528333, "Macro Plagdet": 0.021396753094029754, "Macro Recall": 0.017698831858126186, "Macro Precision": 0.058524538254090576, "Granularity": 1.4119718309859155}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.01986736149907323, "Micro Recall": 0.02629700754964422, "Micro Precision": 0.034749442793041214, "Macro Plagdet": 0.014784901130577822, "Macro Recall": 0.015739529009458145, "Macro Precision": 0.03811697183024677, "Granularity": 1.8419811320754718}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.003201894888486893, "Micro Recall": 0.007301366343759795, "Micro Precision": 0.00298014820808958, "Macro Plagdet": 0.0027140337369778427, "Macro Recall": 0.003895551185206259, "Macro Precision": 0.0033250406598355547, "Granularity": 1.5}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.033569179842184806, "Micro Recall": 0.09698161002375615, "Micro Precision": 0.04629777461254056, "Macro Plagdet": 0.03021818623571502, "Macro Recall": 0.06833364658836026, "Macro Precision": 0.04804197964844435, "Granularity": 2.6478494623655915}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.01725337875361626, "Micro Recall": 0.09174994576979151, "Micro Precision": 0.022480898189394125, "Macro Plagdet": 0.014447900972328382, "Macro Recall": 0.05089887992360215, "Macro Precision": 0.02151069639115449, "Granularity": 3.2666666666666666}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.006075827361328501, "Micro Recall": 0.07591040032048832, "Micro Precision": 0.00593351504834758, "Macro Plagdet": 0.005881889914118028, "Macro Recall": 0.046859295919152645, "Macro Precision": 0.006011119517144248, "Granularity": 2.510204081632653}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-02-20250527-test", "team": "foshan-university", "software": "booming-bridge", "vm": "foshan-university", "run_id": "2025-06-01-14-35-46", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4326.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": true, "review_blinded": false, "evaluation": {"Micro Plagdet": 0.43731068706774895, "Micro Recall": 0.6118848805114745, "Micro Precision": 0.34038214382612536, "Macro Plagdet": 0.33531203354701555, "Macro Recall": 0.6007840808144126, "Macro Precision": 0.23264002486098717, "Granularity": 1.000375633882176}, "used_resources": {"wallcock": "1244191 ms", "CPU (Max)": 10, "RAM (Max)": 20447, "GPU Utilization (Max)": 100, "GPU VRAM (Max)": 3535}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.15524810224193594, "Micro Recall": 0.6050319535183795, "Micro Precision": 0.08906581540663458, "Macro Plagdet": 0.11163346910487801, "Macro Recall": 0.5992935458815004, "Macro Precision": 0.06156060105339952, "Granularity": 1.000231160425335}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.09034743039861615, "Micro Recall": 0.610902505448139, "Micro Precision": 0.048798464294858235, "Macro Plagdet": 0.0637768997296877, "Macro Recall": 0.5994162031839044, "Macro Precision": 0.033692098945723885, "Granularity": 1.000463392029657}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.027406162383041572, "Micro Recall": 0.5799561905887198, "Micro Precision": 0.014049733949744484, "Macro Plagdet": 0.018996458315408932, "Macro Recall": 0.5928169326974434, "Macro Precision": 0.00966315673542942, "Granularity": 1.0014513788098693}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.15140203391356677, "Micro Recall": 0.6137703006227444, "Micro Precision": 0.0863513999878446, "Macro Plagdet": 0.10248766210928402, "Macro Recall": 0.6084767483584745, "Macro Precision": 0.055956277393710126, "Granularity": 1.0}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.10443173386897792, "Micro Recall": 0.6380702806304996, "Micro Precision": 0.056869747994323365, "Macro Plagdet": 0.06839396155849055, "Macro Recall": 0.6292405559999397, "Macro Precision": 0.03616227129428418, "Granularity": 1.0}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.0327411137041221, "Micro Recall": 0.6121695495774686, "Micro Precision": 0.01685298053792866, "Macro Plagdet": 0.021179779180652464, "Macro Recall": 0.6027796687303318, "Macro Precision": 0.010799970402732713, "Granularity": 1.0026178010471205}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.03754290450727251, "Micro Recall": 0.6024420714669475, "Micro Precision": 0.019398015078427516, "Macro Plagdet": 0.032381337684522726, "Macro Recall": 0.537665167512567, "Macro Precision": 0.01671302345510965, "Granularity": 1.0015847860538827}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.019123927879514946, "Micro Recall": 0.58814805099153, "Micro Precision": 0.009719989091815857, "Macro Plagdet": 0.016441482856149953, "Macro Recall": 0.5139664804469274, "Macro Precision": 0.008354367051413642, "Granularity": 1.0}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.005614078503965098, "Micro Recall": 0.5352418553532883, "Micro Precision": 0.002821838189099147, "Macro Plagdet": 0.005308945602905977, "Macro Recall": 0.4801980198019802, "Macro Precision": 0.0026692279497487017, "Granularity": 1.0}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-02-20250527-test", "team": "yukino", "software": "online-auditor", "vm": "yukino", "run_id": "2025-05-30-13-22-52", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4323.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.4385237415055599, "Micro Recall": 0.4170643947431478, "Micro Precision": 0.4625803148541755, "Macro Plagdet": 0.41275826426103324, "Macro Recall": 0.38423432854453304, "Macro Precision": 0.4461227332170545, "Granularity": 1.0003826652635608}, "used_resources": {}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.2091618777621987, "Micro Recall": 0.4609997173006793, "Micro Precision": 0.13530703601341332, "Macro Plagdet": 0.15730534267107235, "Macro Recall": 0.4375438646143736, "Macro Precision": 0.09591636240877743, "Granularity": 1.000315357931252}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.12721245553916716, "Micro Recall": 0.4631909673612638, "Micro Precision": 0.07377026017690877, "Macro Plagdet": 0.09586399063009418, "Macro Recall": 0.4323265162679343, "Macro Precision": 0.05393663165124898, "Granularity": 1.0006349206349205}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.03351053985420982, "Micro Recall": 0.36364507149858816, "Micro Precision": 0.01756457325357441, "Macro Plagdet": 0.01981534731336835, "Macro Recall": 0.36662180199432687, "Macro Precision": 0.010182857591071095, "Granularity": 1.0}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.16555577274966385, "Micro Recall": 0.3779741440697066, "Micro Precision": 0.10602605204424714, "Macro Plagdet": 0.20496532989874752, "Macro Recall": 0.34675186365555144, "Macro Precision": 0.14553367511359686, "Granularity": 1.0003665689149561}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.12090149039108222, "Micro Recall": 0.4006253486327982, "Micro Precision": 0.07119314794334132, "Macro Plagdet": 0.13062280597425452, "Macro Recall": 0.3517323923858423, "Macro Precision": 0.08020409422844198, "Granularity": 1.0}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.03312990803591686, "Micro Recall": 0.31835037372436814, "Micro Precision": 0.017474201727420417, "Macro Plagdet": 0.03161951663961906, "Macro Recall": 0.2954898283916933, "Macro Precision": 0.0167034525257161, "Granularity": 1.0}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.05145464447779713, "Micro Recall": 0.42713551792067905, "Micro Precision": 0.02742171864368463, "Macro Plagdet": 0.051614121892647864, "Macro Recall": 0.38664830720266935, "Macro Precision": 0.027699004044665184, "Granularity": 1.0021645021645023}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.025988596858764, "Micro Recall": 0.4073487397572168, "Micro Precision": 0.013422471093301537, "Macro Plagdet": 0.026484724468930115, "Macro Recall": 0.370545985480969, "Macro Precision": 0.013733149750011199, "Granularity": 1.0}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.007687431625853215, "Micro Recall": 0.3695077499663962, "Micro Precision": 0.003884119434477042, "Macro Plagdet": 0.007220244375466279, "Macro Recall": 0.32981550480019933, "Macro Precision": 0.0036500754898705435, "Granularity": 1.0}}
{"task": "pan25-generated-plagiarism-detection", "dataset": "llm-plagiarism-detection-partition-02-20250527-test", "team": "jrluo", "software": "balanced-fencing", "vm": "jrluo", "run_id": "2025-05-29-11-22-24", "input_run_id": "", "is_evaluation": false, "downloadable": false, "software_id": null, "evaluator_id": null, "docker_software_id": 4313.0, "upload_id": null, "from_upload": null, "reviewed": false, "is_upload": false, "is_docker": true, "review_reviewer": "maik_froebe", "review_noErrors": true, "review_missingOutput": false, "review_extraneousOutput": false, "review_invalidOutput": false, "review_hasErrorOutput": false, "review_otherErrors": false, "review_comment": "", "review_hasErrors": false, "review_hasWarnings": false, "review_hasNoErrors": true, "review_published": false, "review_blinded": true, "evaluation": {"Micro Plagdet": 0.138098907279621, "Micro Recall": 0.10346626715971585, "Micro Precision": 0.5103330316111019, "Macro Plagdet": 0.12018712309018185, "Macro Recall": 0.08751633046325284, "Macro Precision": 0.5180063604986965, "Granularity": 1.3715827338129496}, "used_resources": {"wallcock": "554463 ms", "CPU (Max)": 10, "RAM (Max)": 19660, "GPU Utilization (Max)": 100, "GPU VRAM (Max)": 3508}, "evaluation-DeepSeek-R1-simple": {"Micro Plagdet": 0.14568436709485447, "Micro Recall": 0.1656791697795842, "Micro Precision": 0.21625118566734391, "Macro Plagdet": 0.13827175476478068, "Macro Recall": 0.14810810715005907, "Macro Precision": 0.2232311355720469, "Granularity": 1.4416089965397925}, "evaluation-DeepSeek-R1-medium": {"Micro Plagdet": 0.08104685175233133, "Micro Recall": 0.1251734289459695, "Micro Precision": 0.08865520713557677, "Macro Plagdet": 0.07207870884931844, "Macro Recall": 0.10180768630704128, "Macro Precision": 0.0844341226135143, "Granularity": 1.429553264604811}, "evaluation-DeepSeek-R1-hard": {"Micro Plagdet": 0.027093705475294345, "Micro Recall": 0.09474430457578345, "Micro Precision": 0.02035091194897654, "Macro Plagdet": 0.025454843919678536, "Macro Recall": 0.07602576994317962, "Macro Precision": 0.01984822897773538, "Granularity": 1.3564814814814814}, "evaluation-Llama-3-simple": {"Micro Plagdet": 0.05957211786358586, "Micro Recall": 0.05796695802603845, "Micro Precision": 0.07231058490622524, "Macro Plagdet": 0.059611433423515964, "Macro Recall": 0.05407702842637264, "Macro Precision": 0.0795684064207633, "Granularity": 1.1143131604226706}, "evaluation-Llama-3-medium": {"Micro Plagdet": 0.045686176590776374, "Micro Recall": 0.06218315144406082, "Micro Precision": 0.049140929415354966, "Macro Plagdet": 0.037456278397191844, "Macro Recall": 0.04470057380100815, "Macro Precision": 0.04532116935681135, "Granularity": 1.3}, "evaluation-Llama-3-hard": {"Micro Plagdet": 0.004808377221209031, "Micro Recall": 0.013473155895224938, "Micro Precision": 0.003288760002942069, "Macro Plagdet": 0.004672604009036952, "Macro Recall": 0.010875418345170893, "Macro Precision": 0.0033632759291483795, "Granularity": 1.1428571428571428}, "evaluation-Mistral-simple": {"Micro Plagdet": 0.04664102330843289, "Micro Recall": 0.1412668650301321, "Micro Precision": 0.04033110842448141, "Macro Plagdet": 0.04510524989835946, "Macro Recall": 0.11881258113591217, "Macro Precision": 0.04074615683962769, "Granularity": 1.5408970976253298}, "evaluation-Mistral-medium": {"Micro Plagdet": 0.02229125569173609, "Micro Recall": 0.12054996998421018, "Micro Precision": 0.01766461079125762, "Macro Plagdet": 0.02001583671225489, "Macro Recall": 0.09113650092587522, "Macro Precision": 0.016310110700114386, "Granularity": 1.606896551724138}, "evaluation-Mistral-hard": {"Micro Plagdet": 0.008260108178328701, "Micro Recall": 0.12122418105481773, "Micro Precision": 0.005666686009414867, "Macro Plagdet": 0.007684440149677727, "Macro Recall": 0.09353189444146989, "Macro Precision": 0.005322954919459908, "Granularity": 1.4807692307692308}}
